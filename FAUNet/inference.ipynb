{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import ctypes\n",
    "from torch.autograd import Variable\n",
    "import json\n",
    "import cv2\n",
    "from torch.utils import data\n",
    "from pycocotools.coco import COCO\n",
    "import math\n",
    "from torch.utils.data import DataLoader\n",
    "from unet_utils.dice_score import dice_loss\n",
    "\n",
    "\n",
    "from FAUNet_Train import channel_normalize\n",
    "from FAUNet_Train import myDataset\n",
    "from FAUNet_Train import DoubleConv,Down,Up,OutConv\n",
    "from FAUNet_Train import FAUNet\n",
    "from FAUNet_Train import mynormalize\n",
    "\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def resize_image_cv2(image_array, target_size=(256, 256)):\n",
    "    \"\"\"\n",
    "    Resize an image to a target size using OpenCV.\n",
    "    \n",
    "    Parameters:\n",
    "    - image_array: numpy array of shape (height, width, channels).\n",
    "    - target_size: tuple, target size in (width, height).\n",
    "    \n",
    "    Returns:\n",
    "    - Resized image as a numpy array.\n",
    "    \"\"\"\n",
    "    resized_image = cv2.resize(image_array, target_size, interpolation=cv2.INTER_AREA)\n",
    "    return resized_image\n",
    "\n",
    "Device = 'cuda:0'   \n",
    "\n",
    "\n",
    "activation = {}\n",
    "def get_activation(name):\n",
    "    def hook(model, input, output):\n",
    "        activation[name] = output.detach()\n",
    "    return hook\n",
    "\n",
    "\n",
    "main_path = '/home/geospatial/FAUNet/data_set/'\n",
    "\n",
    "epoch = 96\n",
    "\n",
    "### set paths\n",
    "weights_folder = \"/home/geospatial/FAUNet/FAUNET_weights/\"\n",
    "PATH = weights_folder + \"/weights_\" + str(epoch) + \"epoch_final.pt\"\n",
    "#print('loading model: ', PATH)\n",
    "# resfolder = './unet_res_lowres_full/'\n",
    "\n",
    "#####\n",
    "# faunet = FAUNet(3,2,Device)\n",
    "faunet = torch.load(PATH)\n",
    "# faunet.load_state_dict(PATH)\n",
    "faunet.eval()\n",
    "faunet.to(torch.device(Device))\n",
    "\n",
    "\n",
    "# this is the folder where your test images are \n",
    "pth_images_test = \"/home/geospatial/FAUNet/numpyarrays\"\n",
    "\n",
    "# this is the folder where the results will be written to\n",
    "resfolder = '/home/geospatial/FAUNet/data_set/test_results_india/'\n",
    "os.makedirs(resfolder,exist_ok= True)\n",
    "\n",
    "\n",
    "file_list = os.listdir(pth_images_test)[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ii,file_ in enumerate(file_list):\n",
    "    print(ii,file_)\n",
    "    with torch.no_grad():\n",
    "        im_name = str(ii) \n",
    "        img_dir = file_\n",
    "        im = np.load(pth_images_test + '/' + img_dir).transpose(1,2,0)[:,:,:]\n",
    "        im = resize_image_cv2(im)\n",
    "        \n",
    "        im_h,im_w,im_c = im.shape\n",
    "        if im_h == 256:\n",
    "            if im_h == 256:\n",
    "                im_transposed = np.transpose(im,(2,0,1))\n",
    "                im_tensor = torch.tensor(im_transposed).float()     \n",
    "                x =  im_tensor.to(torch.device(Device)).unsqueeze(0)\n",
    "                c,e = faunet(x)\n",
    "                seg = c.squeeze(0).cpu().numpy()\n",
    "                edges = e.squeeze(0).cpu().numpy()       \n",
    "                \n",
    "                final_res =   1.0*(seg[1,:,:]>0)* (1 - 1.0*(edges[1,:,:]>0))\n",
    "                \n",
    "                # edges = 1.0*(edges[1,:,:]>0)\n",
    "                cv2.imwrite(resfolder + im_name+ '.png',255*im)\n",
    "\n",
    "                # The resulting extent mask\n",
    "                cv2.imwrite(resfolder + im_name + '_resExtent.png',255.0*(seg[1,:,:]>0))\n",
    "                # The resulting edge mask\n",
    "                cv2.imwrite(resfolder + im_name+ '_resEdge.png',255.0*(edges[1,:,:]>0))\n",
    "                final_res = final_res.astype('uint8')\n",
    "                # this is the postprocessed result (close parcels)\n",
    "                cv2.imwrite(resfolder + im_name+ '_final_res.png',255.0*final_res)\n",
    "                \n",
    "                fig,axs=plt.subplots(1,4,figsize=(15,15))\n",
    "                axs[0].imshow(im)\n",
    "                axs[1].imshow(seg[1,:,:]>0)\n",
    "                axs[2].imshow(edges[1,:,:]>0)\n",
    "                axs[3].imshow(final_res*255)\n",
    "                for ax in axs.ravel():\n",
    "                    ax.set_axis_off()\n",
    "                plt.show()\n",
    "                print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from inference import get_prediction_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 cluster_image_232_0.1_5_5_0.005.tif_tile_0.npy\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "for ii,file_ in enumerate(file_list):\n",
    "    print(ii,file_)\n",
    "    with torch.no_grad():\n",
    "        im_name = str(ii) \n",
    "        img_dir = file_\n",
    "        im = np.load(pth_images_test + '/' + img_dir).transpose(1,2,0)[:,:,:]\n",
    "        im = resize_image_cv2(im)\n",
    "        \n",
    "        prediction=get_prediction_map(im,\"/home/geospatial/FAUNet/FAUNET_weights/weights_96epoch_final.pt\")\n",
    "        print(prediction)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
